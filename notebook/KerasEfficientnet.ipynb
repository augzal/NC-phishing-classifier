{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022d70d-8aed-4b2b-9811-d8174b64d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4968aa4-6d23-42c5-895b-1297650358b0",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Based on visual inspection of the dataset, there are some duplicate images found. Use hash to encode images and find duplicates. Create deduplicated dataset, by selecting only the first image of identified duplicates and moving it to a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2135b-ef36-41be-a4ae-17813d17d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob('../data/train_data/**/*.jpeg', recursive = True)\n",
    "print('Number of images found:', len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec7a37-a359-4eaf-bf11-26d4d9336a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "hash_img_map = {}\n",
    "for image_path in image_paths:\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        img_hash = hashlib.sha256(f.read()).hexdigest()\n",
    "        hash_img_map[img_hash] = hash_img_map.get(img_hash, []) + [image_path]\n",
    "hash_img_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d793a12-d1f2-46e0-a13f-b695d54a32a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check samples of duplicated images (display up to 3 images)\n",
    "from PIL import Image\n",
    "\n",
    "check_hash = '7cd910ccf43da503a9dc10a12bdd699f5ef7601aedf8534006e54a6efe01d41d'\n",
    "for i, image in enumerate(hash_img_map[check_hash]):\n",
    "    with Image.open(image) as im:\n",
    "        display(im)\n",
    "    if i >= 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27a17d-5b00-4ce2-89e0-fc3fedc2f24e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if there are duplicates between different classes, by comparing paths in image names\n",
    "import os \n",
    "\n",
    "for file, img_paths in hash_img_map.items():\n",
    "    same_img_paths = []\n",
    "    for img_path in img_paths:\n",
    "        same_img_paths.append('/'.join(img_path.split('/')[:4]))\n",
    "    if len(set(same_img_paths)) > 1:\n",
    "        print('----------')\n",
    "        print(img_paths)\n",
    "        print(set(same_img_paths))\n",
    "\n",
    "# No duplicates found between different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd649a5-40a3-4ed6-a32e-f9bccb41311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedup (take the first file) and move to a new folder\n",
    "import shutil\n",
    "\n",
    "for file, img_paths in hash_img_map.items():\n",
    "    src = img_paths[0]\n",
    "    dst = img_paths[0].replace('train_data', 'train_data_dedup')\n",
    "    os.makedirs(os.path.split(dst)[0], exist_ok=True)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d0ca7-978d-4986-a413-7d1de2eaaeba",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81896059-437c-4cba-a084-05d5f2418c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "img_shape = (256, 256, 3)\n",
    "\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory='../data/train_data_dedup',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=8,\n",
    "    image_size=(img_shape[0], img_shape[1]),\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    seed=235,\n",
    "    subset=\"both\",)\n",
    "\n",
    "num_classes = len(train_ds.class_names)\n",
    "others_class_id = train_ds.class_names.index('others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a41d7-da48-4de7-b035-249b429f4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some of the images with labels\n",
    "for image, label in train_ds.take(1):\n",
    "    for i in range(image.shape[0]):\n",
    "        ax = plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(image[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"{}\".format(train_ds.class_names[np.argmax(label[i])]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8adeb-961c-420e-965e-eee6f8cde278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check classes distributions\n",
    "import plotly.express as px \n",
    "\n",
    "train_labels = []\n",
    "for _, batch_class_ids in train_ds:\n",
    "    for class_ids in batch_class_ids:\n",
    "        train_labels.append(train_ds.class_names[np.argmax(class_ids)])\n",
    "\n",
    "fig = px.histogram(train_labels, text_auto=True).update_xaxes(categoryorder='category ascending')\n",
    "fig.update_layout(showlegend=False, xaxis_title=\"classes\", title=\"Distribution of train dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c79773-956c-4bbb-940e-71678b94f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for _, batch_class_ids in val_ds:\n",
    "    for class_ids in batch_class_ids:\n",
    "        val_labels.append(val_ds.class_names[np.argmax(class_ids)])\n",
    "\n",
    "fig = px.histogram(val_labels, text_auto=True).update_xaxes(categoryorder='category ascending')\n",
    "fig.update_layout(showlegend=False, xaxis_title=\"classes\", title=\"Distribution of val dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de775f94-5016-4c04-86f2-5a090f850b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984139d-bd69-453b-a4e2-6ef15137483e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "model = EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    classes=num_classes,\n",
    "    input_shape=img_shape,\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"CategoricalFocalCrossentropy\", metrics=[\"recall\", Recall(class_id=9, name='recall_others'), \"auc\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280208a-24f4-479c-ab84-37f0dd185323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db89ef-eca4-4f94-99a2-d5a44454e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19d211-db12-4454-86fd-2da02d14d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0\n",
    ")\n",
    "logdir=\"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdfbb1-8f5d-407c-b202-d9d2ba9cacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "hist = model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[early_stopping_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50825dee-dd91-4fd5-8a37-ecca067cf6f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist.model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa230b06-d574-464b-9d88-acbd584e6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../model/efficientnet_othersfocused.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d65b67-f355-45be-9e90-1b118774eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../model/efficientnetb0.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d4afe-19d8-4275-ac8e-fbd295d087d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf603ae-d6c4-4aed-9ebe-41c5471278bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "            \"Facebook, Inc.\",\n",
    "            \"Microsoft\",\n",
    "            \"Microsoft OneDrive\",\n",
    "            \"Orange\",\n",
    "            \"Spotify\",\n",
    "            \"Steam\",\n",
    "            \"UPS\",\n",
    "            \"Vodafone\",\n",
    "            \"Wells Fargo & Company\",\n",
    "            \"others\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb20fbc-5b64-478c-afa6-e3727cb082cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = []\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "for pred_class in pred_classes:\n",
    "    pred_labels.append(labels[pred_class])\n",
    "\n",
    "\n",
    "val_labels = []\n",
    "for _, batch_class_ids in val_ds:\n",
    "    for class_ids in batch_class_ids:\n",
    "        val_labels.append(val_ds.class_names[np.argmax(class_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92645b52-ef12-4f41-92f9-6d881c3ad9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "sr = classification_report(val_labels, pred_labels, zero_division=0)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb270e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_labels, pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()\n",
    "disp.ax_.tick_params(axis='x', labelrotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
